{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-pytorch-Neural_Network_Training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1dhiman/100days-ml/blob/master/2019/3_pytorch_Neural_Network_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdxTc9YqMpqC",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Training \n",
        "\n",
        "Training by learning how to iterate over data, calculating loss, and then doing backpropagation to slowly fit model to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRiEjPuRMYGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "efd36da5-41e5-4547-d2d1-48fa20722c09"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train = datasets.MNIST('', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "test = datasets.MNIST('', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELfZqHONHFi",
        "colab_type": "text"
      },
      "source": [
        "Next, we want to calculate loss and specify our optimizer:\n",
        "\n",
        "* `loss_function` is what calculates \"how far off\" our classifications are from reality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYSPupu5NBtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61YtlNOVNJtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f09c3889-6f26-4b83-d44e-46900da2ca2e"
      },
      "source": [
        "for epoch in range(3): # 3 full passes over the data\n",
        "    for data in trainset:  # `data` is a batch of data\n",
        "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
        "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
        "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
        "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
        "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
        "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines!"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1813, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHyoXnHPOoZU",
        "colab_type": "text"
      },
      "source": [
        "Iterate over our test set, measuring for correctness by comparing output to target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LY2znyUOdVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f158ad64-e18e-4226-9697-f5bc4229c46e"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testset:\n",
        "        X, y = data\n",
        "        output = net(X.view(-1,784))\n",
        "        #print(output)\n",
        "        for idx, i in enumerate(output):\n",
        "            #print(torch.argmax(i), y[idx])\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wuxk1YwOx97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "5f1ce145-ac4e-40a3-e8d4-8b4ba904800f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[0].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kNT/AcuyB/+MFbVaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72hABG5mO4xV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f179c85b-6d0c-432f-f9d6-a60b06a4c96a"
      },
      "source": [
        "print(torch.argmax(net(X[0].view(-1,784))[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSPUxhETO8lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}