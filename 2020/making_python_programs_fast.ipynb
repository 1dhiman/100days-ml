{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "making_python_programs_fast.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyuTWNwhYyh8GDrUXfr0jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1dhiman/100days-ml/blob/master/2020/making_python_programs_fast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B20BohmRd89s",
        "colab_type": "text"
      },
      "source": [
        "# Making Python Programs Fast\n",
        "\n",
        "## Timing and Profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztrs8knUdsud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e1a0a05-3a6d-4232-ae27-ac2c22ee0e52"
      },
      "source": [
        "# slow_program.py\n",
        "# it computes e to power of X\n",
        "from decimal import *\n",
        "\n",
        "def exp(x):\n",
        "    getcontext().prec += 2\n",
        "    i, lasts, s, fact, num = 0, 0, 1, 1, 1\n",
        "    while s != lasts:\n",
        "        lasts = s\n",
        "        i += 1\n",
        "        fact *= i\n",
        "        num *= x\n",
        "        s += num / fact\n",
        "    getcontext().prec -= 2\n",
        "    return +s\n",
        "\n",
        "exp(Decimal(150))\n",
        "exp(Decimal(400))\n",
        "exp(Decimal(3000))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decimal('1.393709580666379697318341937E+65')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzRJYbsoeftl",
        "colab_type": "text"
      },
      "source": [
        "#### Timing Specific Functions\n",
        "\n",
        "We might want to time the slow function, without measuring rest of the code. For that we can use simple decorator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg68JNGseNBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import wraps\n",
        "import time\n",
        "\n",
        "def timeit_wrapper(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.perf_counter()  # Alternatively, you can use time.process_time()\n",
        "        func_return_val = func(*args, **kwargs)\n",
        "        end = time.perf_counter()\n",
        "        print('{0:<10}.{1:<8} : {2:<8}'.format(func.__module__, func.__name__, end - start))\n",
        "        return func_return_val\n",
        "    return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwpm0UccevKL",
        "colab_type": "text"
      },
      "source": [
        "This decorator can be then applied to function under test like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arNG401Zeqyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "67ab7c79-b277-4e51-c9de-552451145067"
      },
      "source": [
        "@timeit_wrapper\n",
        "def exp(x):\n",
        "    getcontext().prec += 2\n",
        "    i, lasts, s, fact, num = 0, 0, 1, 1, 1\n",
        "    while s != lasts:\n",
        "        lasts = s\n",
        "        i += 1\n",
        "        fact *= i\n",
        "        num *= x\n",
        "        s += num / fact\n",
        "    getcontext().prec -= 2\n",
        "    return +s\n",
        "\n",
        "print('{0:<10} {1:<8} {2:^8}'.format('module', 'function', 'time'))\n",
        "exp(Decimal(150))\n",
        "exp(Decimal(400))\n",
        "exp(Decimal(3000))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module     function   time  \n",
            "__main__  .exp      : 0.004896852999991097\n",
            "__main__  .exp      : 0.05113874599999235\n",
            "__main__  .exp      : 14.764340761000085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decimal('7.646200989054704889310727660E+1302')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJEbpZWfZ5a",
        "colab_type": "text"
      },
      "source": [
        "One thing to consider is what kind of time we actually (want to) measure. Time package provides `time.perf_counter` and `time.process_time`. The difference here is that `perf_counter` returns absolute value, which includes time when your Python program process is not running, therefore it might be impacted by machine load. On the other hand `process_time` returns only user time (excluding system time), which is only the time of your process.\n",
        "\n",
        "## Making It Faster\n",
        "\n",
        "**Use Built-in Data Types**\n",
        "\n",
        "Built-in data types are very fast, especially in comparison to our custom types like trees or linked lists. That's mainly because the built-ins are implemented in C, which we can't really match in speed when coding in Python.\n",
        "\n",
        "**Use Local Variables**\n",
        "\n",
        "This has to do with speed of lookup of variables in each scope. There's actually difference in speed of lookup even between - let's say - local variable in function (fastest), class-level attribute (e.g. self.name - slower) and global for example imported function like time.time (slowest).\n",
        "\n",
        "You can improve performance, by using seemingly unnecessary (straight-up useless) assignments like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YNxCSgUeyRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Example #1\n",
        "class FastClass:\n",
        "\n",
        "    def do_stuff(self):\n",
        "        temp = self.value  # this speeds up lookup in loop\n",
        "        for i in range(10000):\n",
        "            ...  # Do something with `temp` here\n",
        "\n",
        "#  Example #2\n",
        "import random\n",
        "\n",
        "def fast_function():\n",
        "    r = random.random\n",
        "    for i in range(10000):\n",
        "        print(r())  # calling `r()` here, is faster than global random.random()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71AfFDosgx9k",
        "colab_type": "text"
      },
      "source": [
        "**Use Functions**\n",
        "\n",
        "This might seem counter intuitive, as calling function will put more stuff onto stack and create overhead from function returns, but it relates to previous point. If you just put your whole code into one file without putting it into function, it will be much slower because of global variables. Therefore you can speed up your code just by wrapping whole code in main function and calling it once, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjDoAL8sgwr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    ...  # All your previously global code\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGhOEklHhIjK",
        "colab_type": "text"
      },
      "source": [
        "**Don't Access Attributes**\n",
        "\n",
        "Another thing that might slow down your programs is dot operator (`.`) which is used when accessing object attributes. This operator triggers dictionary lookup using `__getattribute__`, which creates extra overhead in your code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1BIM2lshUlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Slow:\n",
        "import re\n",
        "\n",
        "def slow_func():\n",
        "    for i in range(10000):\n",
        "        re.findall(regex, line)  # Slow!\n",
        "\n",
        "#  Fast:\n",
        "from re import findall\n",
        "\n",
        "def fast_func():\n",
        "    for i in range(10000):\n",
        "        findall(regex, line)  # Faster!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7MvjSpAheGJ",
        "colab_type": "text"
      },
      "source": [
        "**Beware of Strings**\n",
        "\n",
        "Operations on strings can get quite slow when ran in loop using for example modulus (`%s`) or `.format()`. The only thing we should be using is `f-string`, it's most readable, concise AND the fastest method. This is the list of methods you can use - fastest to slowest:\n",
        "\n",
        "```\n",
        "f'{s} {t}'  # Fast!\n",
        "s + '  ' + t\n",
        "' '.join((s, t))\n",
        "'%s %s' % (s, t)\n",
        "'{} {}'.format(s, t)\n",
        "Template('$s $t').substitute(s=s, t=t)  # Slow!\n",
        "```\n",
        "\n",
        "**Generators Can Be Fast**\n",
        "\n",
        "Generators are not inherently faster as they were made to allow for lazy computation, which saves memory rather than time. However, the saved memory can be cause for your program to actually run faster. How? Well, if you have large dataset and you don't use generators (iterators), then the data might overflow CPUs L1 cache, which will slow down lookup of values in memory significantly.\n",
        "\n",
        "When it comes to performance, it's very import that CPU can save all the data it's working on, as close as possible, which is in the cache.\n",
        "\n",
        "[Source](https://martinheinz.dev/blog/13)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNCEV1oRhrzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}